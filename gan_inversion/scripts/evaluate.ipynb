{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGet3CG2VcD1"
      },
      "source": [
        "# Set Up Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYLrG-Gw5CvC",
        "outputId": "77d1d7b8-9d93-4497-c867-97e8e11495b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/Datasets/shared/celeba/CelebA-HQ-img.zip\n"
          ]
        }
      ],
      "source": [
        "# Unzip image files\n",
        "\n",
        "!!unzip \"/content/gdrive/My Drive/Datasets/shared/celeba/CelebA-HQ-img.zip\" -d \"/content/gdrive/My Drive/Datasets/shared/celeba/CelebA-HQ-img/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pl5ACIkbJX3U",
        "outputId": "2f7e3618-b5fa-46c3-ee99-20fa5c05c7c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting beautifulsoup4==4.11.1\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 30 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 40 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 51 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 128 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi==2021.10.8 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer==2.0.12 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 3)) (2.0.12)\n",
            "Collecting click==8.0.4\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 5)) (0.11.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting filelock==3.4.1\n",
            "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 8)) (4.4.0)\n",
            "Collecting idna==3.3\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata==4.8.3\n",
            "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
            "Collecting importlib-resources==5.4.0\n",
            "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
            "Collecting kiwisolver==1.3.1\n",
            "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 48.3 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.4\n",
            "  Downloading matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 28.0 MB/s \n",
            "\u001b[?25hCollecting ninja==1.10.2.3\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 85.5 MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 63.5 MB/s \n",
            "\u001b[?25hCollecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 14.4 MB/s \n",
            "\u001b[?25hCollecting Pillow==8.4.0\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing==3.0.8 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 18)) (3.0.8)\n",
            "Requirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 19)) (1.7.1)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 20)) (2.8.2)\n",
            "Requirement already satisfied: pytz==2022.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 21)) (2022.1)\n",
            "Collecting requests==2.27.1\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting scipy==1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 5.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn==0.11.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 24)) (0.11.2)\n",
            "Collecting six==1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting soupsieve==2.3.2\n",
            "  Downloading soupsieve-2.3.2-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 27)) (1.1.0)\n",
            "Collecting torch==1.10.1\n",
            "  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:41tcmalloc: large alloc 1147494400 bytes == 0x4106000 @  0x7fddb3a09615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 15 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.11.2\n",
            "  Downloading torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.3 MB 73.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 30)) (4.64.0)\n",
            "Collecting typing_extensions==4.1.1\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting urllib3==1.26.9\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 73.2 MB/s \n",
            "\u001b[?25hCollecting zipp==3.6.0\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->-r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt (line 8)) (2.23.0)\n",
            "Installing collected packages: urllib3, six, idna, zipp, typing-extensions, soupsieve, requests, Pillow, numpy, kiwisolver, torch, scipy, pandas, matplotlib, importlib-metadata, filelock, beautifulsoup4, torchvision, ninja, importlib-resources, dataclasses, click\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.8.0\n",
            "    Uninstalling zipp-3.8.0:\n",
            "      Successfully uninstalled zipp-3.8.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.3.2.post1\n",
            "    Uninstalling soupsieve-2.3.2.post1:\n",
            "      Successfully uninstalled soupsieve-2.3.2.post1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.2\n",
            "    Uninstalling kiwisolver-1.4.2:\n",
            "      Successfully uninstalled kiwisolver-1.4.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.6.0\n",
            "    Uninstalling filelock-3.6.0:\n",
            "      Successfully uninstalled filelock-3.6.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.7.1\n",
            "    Uninstalling importlib-resources-5.7.1:\n",
            "      Successfully uninstalled importlib-resources-5.7.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.10.1 which is incompatible.\n",
            "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.4.0 beautifulsoup4-4.11.1 click-8.0.4 dataclasses-0.6 filelock-3.4.1 idna-3.3 importlib-metadata-4.8.3 importlib-resources-5.4.0 kiwisolver-1.3.1 matplotlib-3.3.4 ninja-1.10.2.3 numpy-1.19.5 pandas-1.1.5 requests-2.27.1 scipy-1.5.4 six-1.16.0 soupsieve-2.3.2 torch-1.10.1 torchvision-0.11.2 typing-extensions-4.1.1 urllib3-1.26.9 zipp-3.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# set up environment with requirements.txt \n",
        "\n",
        "!pip install -r /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkJo66SUVi-D"
      },
      "source": [
        "# Set up working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBy54FqEA8ji",
        "outputId": "32f0595e-ed83-4a61-c6f0-e66b84462b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# set up working directory and mount google drive \n",
        "use_colab = True\n",
        "\n",
        "if use_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    #!ls \"/content/gdrive/My Drive/Datasets/shared/HW4_shared_files\"\n",
        "\n",
        "    ## Update the experiments directory\n",
        "    EXPERIMENTS_DIRECTORY = '/content/gdrive/My Drive/Datasets/shared/experiments/'\n",
        "    DATA_DIRECTORY = '/content/gdrive/My Drive/Datasets/shared/celeba/'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change working directory\n",
        "\n",
        "%cd /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/restyle_encoder/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R3jXqWxrq7y",
        "outputId": "a8ca1711-bf1f-4ef4-81bb-79dd563c813f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/restyle_encoder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attributes "
      ],
      "metadata": {
        "id": "W0Sgtkb0pj7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in attribute annotation files\n",
        "\n",
        "attributes_file = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/CelebAMask-HQ-attribute-anno.txt'\n",
        "\n",
        "from pandas import DataFrame, read_csv\n",
        "import pandas as pd\n",
        "df = pd.read_csv(attributes_file, sep='\\t')"
      ],
      "metadata": {
        "id": "SQW5E4knpi0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxtArDentD4x",
        "outputId": "5d96222b-d6b9-47ac-c23a-65f6e35524bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['filename', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
            "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
            "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
            "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
            "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
            "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
            "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
            "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
            "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
            "       'Wearing_Necktie', 'Young'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter all images with attribute (Not Young)\n",
        "newdf = df[df['Young'] != 1]\n",
        "newdf = newdf.reset_index()\n",
        "print(newdf['filename'])\n",
        "\n",
        "print(newdf['filename'][0:20])\n",
        "\n",
        "\n",
        "not_young_files = []\n",
        "for fn in range(len(newdf)):\n",
        "  not_young_files.append(newdf['filename'][fn])"
      ],
      "metadata": {
        "id": "IbF-M0O6uTXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy images with attribute to new folder\n",
        "\n",
        "scr_folder = '/content/gdrive/MyDrive/Datasets/shared/celeba/CelebA-HQ-img/CelebA-HQ-img/'\n",
        "cp_folder = '/content/gdrive/MyDrive/Datasets/shared/celeba/not_young/'\n",
        "import os\n",
        "import shutil\n",
        "os.makedirs(cp_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "for file_name in not_young_files:\n",
        "    # construct full file path\n",
        "    source = scr_folder + file_name\n",
        "    destination = cp_folder + file_name\n",
        "    # copy only files\n",
        "    if os.path.isfile(source):\n",
        "        shutil.copy(source, destination)\n",
        "        print('copied', file_name)"
      ],
      "metadata": {
        "id": "rieOoX_oZo7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter all images with attribute (Heavy Makeup)\n",
        "newdf = df[df['Heavy_Makeup'] == 1]\n",
        "\n",
        "newdf = newdf.reset_index()\n",
        "print(newdf['filename'])\n",
        "\n",
        "print(newdf['filename'][0:20])\n",
        "\n",
        "# copy images with attribute to new folder\n",
        "not_young_files = []\n",
        "for fn in range(len(newdf)):\n",
        "  not_young_files.append(newdf['filename'][fn])\n",
        "\n",
        "scr_folder = '/content/gdrive/MyDrive/Datasets/shared/celeba/CelebA-HQ-img/CelebA-HQ-img/'\n",
        "cp_folder = '/content/gdrive/MyDrive/Datasets/shared/celeba/Heavy_Makeup/'\n",
        "\n",
        "os.makedirs(cp_folder, exist_ok=True)\n",
        "for file_name in not_young_files:\n",
        "    # construct full file path\n",
        "    source = scr_folder + file_name\n",
        "    destination = cp_folder + file_name\n",
        "    # copy only files\n",
        "    if os.path.isfile(source):\n",
        "        shutil.copy(source, destination)\n",
        "        print('copied', file_name)"
      ],
      "metadata": {
        "id": "l6eBFOalcI5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFceuDfxVqDr"
      },
      "source": [
        "# psp stylegan2 attention "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wgyakbBrekCW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from tqdm import trange \n",
        "import argparse\n",
        "\n",
        "from argparse import Namespace\n",
        "import torch\n",
        "\n",
        "from models.psp import pSp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVd0zUlIsUEm",
        "outputId": "e12a725a-c6c6-4ac0-a3b3-4e4e67f26a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'exp_dir': 'experiment/psp_stylegan_attention_ffhq_encode7', 'dataset_type': 'ffhq_encode', 'encoder_type': 'GradualStyleEncoder', 'use_attention': True, 'use_gansformer': False, 'use_stylegan': False, 'input_nc': 3, 'output_size': 256, 'device': 'cuda:0', 'batch_size': 8, 'test_batch_size': 2, 'workers': 40, 'test_workers': 8, 'learning_rate': 9e-05, 'optim_name': 'ranger', 'train_decoder': False, 'start_from_latent_avg': True, 'lpips_lambda': 0.8, 'id_lambda': 0.1, 'l2_lambda': 1.0, 'w_norm_lambda': 0.0, 'lpips_lambda_crop': 0, 'l2_lambda_crop': 0, 'moco_lambda': 0, 'stylegan_weights': 'pretrained_models/stylegan2-ffhq-config-f.pt', 'checkpoint_path': 'experiment/psp_stylegan_attention_ffhq_encode6/checkpoints/best_model.pt', 'max_steps': 500000, 'image_interval': 100, 'board_interval': 50, 'val_interval': 5000, 'save_interval': 10000, 'n_iters_per_batch': 5, 'use_amp': False}\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/psp_stylegan2_attention_ffhq_500k.pt'\n",
        "#mod = torch.load(model,map_location='cpu')\n",
        "mod = torch.load(model,map_location='cuda:0')\n",
        "mod['opts']['use_attention'] = True\n",
        "print(mod['opts'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in mod['opts'].keys():\n",
        "  print(key + \": \" + str(mod['opts'][key]))\n",
        "  #print(mod['opts'][key])"
      ],
      "metadata": {
        "id": "EBr_1Z6uv-vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmO3DZhtgfaN",
        "outputId": "a4d7ba95-4a78-46c2-8bff-9e142de3efa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading encoder\n",
            "GradualStyleEncoder\n",
            "Loading ReStyle pSp from checkpoint: /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/psp_stylegan2_attention_ffhq_500k.pt\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "#test_opts = testoptions().parse()\n",
        "opts = mod['opts']\n",
        "opts['latent_avg'] = mod['latent_avg']\n",
        "opts['dataset_type']='ffhq_encode'\n",
        "opts['resize_outputs'] = True\n",
        "#opts.update(vars(testoptions().parse()))\n",
        "opts = Namespace(**opts)\n",
        "opts.checkpoint_path = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/psp_stylegan2_attention_ffhq_500k.pt'\n",
        "net = pSp(opts).to(device)\n",
        "#print(net)\n",
        "#net = pSps(opts,mod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4sk228EG3-ez"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "from configs import data_configs\n",
        "from datasets.inference_dataset import InferenceDataset\n",
        "\n",
        "from models.psp import pSp\n",
        "\n",
        "from utils.common import tensor2im\n",
        "from utils.inference_utils import run_on_batch, get_average_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dtvK0o04VK7",
        "outputId": "0af5d128-b5ad-4d7b-a8c1-e6e2b2bead9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f1bd407a390>\n",
            "torch.Size([3, 256, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/19 [00:04<01:12,  4.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 2/19 [00:07<01:04,  3.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 3/19 [00:11<00:59,  3.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 4/19 [00:15<00:55,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 5/19 [00:18<00:51,  3.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 6/19 [00:22<00:48,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 7/19 [00:26<00:44,  3.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 8/19 [00:29<00:40,  3.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 9/19 [00:33<00:37,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 10/19 [00:37<00:33,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 11/19 [00:40<00:29,  3.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 12/19 [00:44<00:26,  3.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 13/19 [00:48<00:22,  3.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 14/19 [00:52<00:18,  3.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 15/19 [00:56<00:15,  3.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 16/19 [00:59<00:11,  3.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 17/19 [01:03<00:07,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 18/19 [01:07<00:03,  3.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [01:08<00:00,  3.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime 3.1954+-0.5344\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/famous/'\n",
        "\n",
        "#data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/CelebA-HQ-img/CelebA-HQ-img/'\n",
        "exp_dir = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/experiment/famous/'\n",
        "exp_path_results = os.path.join(exp_dir, 'psp_stylegan2_attention')\n",
        "os.makedirs(exp_path_results, exist_ok=True)\n",
        "\n",
        "out_path_results = os.path.join('/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/', 'famous/psp_stylegan2_attention')\n",
        "os.makedirs(out_path_results, exist_ok=True)\n",
        "\n",
        "dataset_args = data_configs.DATASETS[opts.dataset_type]\n",
        "#print(dataset_args)\n",
        "transforms_dict = dataset_args['transforms'](opts).get_transforms()\n",
        "\n",
        "#dpath = os.path.join('/content/gdrive/MyDrive/Datasets/shared/celeba/CelebA-HQ-img/','CelebA-HQ-img/')\n",
        "#print(transforms_dict)\n",
        "#print(os.path.isdir(data_path))\n",
        "dataset = InferenceDataset(root=data_path,\n",
        "                           transform=transforms_dict['transform_inference'],\n",
        "                           opts=opts)\n",
        "\n",
        "##print(dataset)\n",
        "dataloader = DataLoader(dataset, \n",
        "                        batch_size=opts.batch_size,\n",
        "                        shuffle=False,\n",
        "                        num_workers=int(4),\n",
        "                        drop_last=False)\n",
        "n_images = len(dataset)\n",
        "print(dataloader)\n",
        "avg_image = get_average_image(net, opts)\n",
        "print(avg_image.size())\n",
        "global_i = 0\n",
        "global_time = []\n",
        "all_latents = {}\n",
        "#print(opts.test_workers)\n",
        "resize_amount = (256, 256)\n",
        "for input_batch in tqdm(dataloader):\n",
        "  #print(global_i)\n",
        "  if global_i >= n_images:break\n",
        "  with torch.no_grad():\n",
        "    input_cuda = input_batch.cuda().float()\n",
        "    tic = time.time()\n",
        "    result_batch, result_latents = run_on_batch(input_cuda, net, opts, avg_image)\n",
        "    toc = time.time()\n",
        "    global_time.append(toc - tic)\n",
        "  for i in range(input_batch.shape[0]):\n",
        "    results = [tensor2im(result_batch[i][iter_idx]) for iter_idx in range(opts.n_iters_per_batch)]\n",
        "    im_path = dataset.paths[global_i]\n",
        "\n",
        "    # save step-by-step results side-by-side\n",
        "    \n",
        "    for idx, result in enumerate(results):\n",
        "      save_dir = os.path.join(out_path_results, str(idx))\n",
        "      os.makedirs(save_dir, exist_ok=True)\n",
        "      result.resize(resize_amount).save(os.path.join(save_dir, os.path.basename(im_path)))\n",
        "\n",
        "    # store all latents with dict pairs (image_name, latents)\n",
        "    all_latents[os.path.basename(im_path)] = result_latents[i]\n",
        "\n",
        "    global_i += 1\n",
        "\n",
        "stats_path = os.path.join(exp_path_results, 'stats.txt')\n",
        "result_str = 'Runtime {:.4f}+-{:.4f}'.format(np.mean(global_time), np.std(global_time))\n",
        "print(result_str)\n",
        "\n",
        "with open(stats_path, 'w') as f:\n",
        "    f.write(result_str)\n",
        "\n",
        "# save all latents as npy file\n",
        "np.save(os.path.join(exp_path_results, 'latents.npy'), all_latents)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KySIF7gQVxv_"
      },
      "source": [
        "# psp gansformer attention "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dgNtIWRJkZjV"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from argparse import Namespace\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import sys\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from models.psp_gansformer import pSpGansformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyClyFJoO0l3",
        "outputId": "1c4ef821-a0fc-4f10-ef1d-3fcb89ed1859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'exp_dir': 'experiment/psp_attention_ffhq_encode8', 'dataset_type': 'ffhq_encode', 'encoder_type': 'GradualStyleEncoder', 'use_attention': False, 'use_gansformer': True, 'use_stylegan': False, 'input_nc': 3, 'output_size': 256, 'device': 'cuda:1', 'batch_size': 8, 'test_batch_size': 2, 'workers': 40, 'test_workers': 8, 'learning_rate': 9e-05, 'optim_name': 'ranger', 'train_decoder': False, 'start_from_latent_avg': True, 'lpips_lambda': 0.8, 'id_lambda': 0.1, 'l2_lambda': 1.0, 'w_norm_lambda': 0.0, 'lpips_lambda_crop': 0, 'l2_lambda_crop': 0, 'moco_lambda': 0, 'stylegan_weights': 'pretrained_models/ffhq-gansformer-256.pkl', 'checkpoint_path': 'experiment/psp_attention_ffhq_encode7/checkpoints/best_model.pt', 'max_steps': 500000, 'image_interval': 100, 'board_interval': 50, 'val_interval': 5000, 'save_interval': 10000, 'n_iters_per_batch': 5, 'use_amp': True}\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/psp_gansformer_attention_ffhq_500k.pt'\n",
        "mod = torch.load(model,map_location='cuda:0')\n",
        "#mod['opts']['use_attention'] = True\n",
        "print(mod['opts'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nkSUBLh8P37a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4178901-a83b-4a75-9bed-ef30ce16806d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ReStyle pSp from checkpoint: /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/psp_gansformer_attention_ffhq_500k.pt\n",
            "https://drive.google.com/uc?id=1tgs-hHaziWrh0piuX3sEd8PwE9gFwlNh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tgs-hHaziWrh0piuX3sEd8PwE9gFwlNh\n",
            "To: /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/restyle_encoder/ffhq-snapshot.pkl\n",
            "100%|██████████| 367M/367M [00:03<00:00, 122MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.BufferedReader name='ffhq-snapshot.pkl'>\n",
            "dnnlib.tflib.network\n",
            "Network\n",
            "numpy.core.multiarray\n",
            "_reconstruct\n",
            "numpy\n",
            "ndarray\n",
            "numpy\n",
            "dtype\n",
            "numpy.core.multiarray\n",
            "scalar\n"
          ]
        }
      ],
      "source": [
        "opts = mod['opts']\n",
        "opts['latent_avg'] = mod['latent_avg']\n",
        "opts['dataset_type']='ffhq_encode'\n",
        "opts['resize_outputs'] = True\n",
        "opts['stylegan_weights']='https://drive.google.com/uc?id=1tgs-hHaziWrh0piuX3sEd8PwE9gFwlNh'\n",
        "opts['device']='cuda:0'\n",
        "opts = Namespace(**opts)\n",
        "opts.checkpoint_path = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/psp_gansformer_attention_ffhq_500k.pt'\n",
        "net = pSpGansformer(opts).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s5f-iHMrP37a"
      },
      "outputs": [],
      "source": [
        "from configs import data_configs\n",
        "from datasets.inference_dataset import InferenceDataset\n",
        "\n",
        "from utils.common import tensor2im\n",
        "from utils.inference_utils import run_on_batch, get_average_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-fhActFP37a",
        "outputId": "6f42227f-b8f1-428b-de87-89bbd0e87c2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f1bd1cdb790>\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "torch.Size([3, 256, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/19 [00:04<01:24,  4.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 2/19 [00:08<01:14,  4.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 3/19 [00:13<01:08,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 4/19 [00:17<01:04,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 5/19 [00:21<00:59,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 6/19 [00:25<00:55,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 7/19 [00:30<00:51,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 8/19 [00:34<00:46,  4.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 9/19 [00:38<00:42,  4.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 10/19 [00:42<00:38,  4.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 11/19 [00:47<00:34,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 12/19 [00:51<00:30,  4.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 13/19 [00:55<00:25,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 14/19 [01:00<00:21,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 15/19 [01:04<00:17,  4.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 16/19 [01:08<00:13,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 17/19 [01:13<00:08,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 18/19 [01:17<00:04,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [01:19<00:00,  4.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime 3.7426+-0.6167\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/famous/'\n",
        "exp_dir = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/experiment/famous/'\n",
        "exp_path_results = os.path.join(exp_dir, 'psp_gansformer_attention')\n",
        "os.makedirs(exp_path_results, exist_ok=True)\n",
        "\n",
        "out_path_results = os.path.join('/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/', 'famous/psp_gansformer_attention')\n",
        "os.makedirs(out_path_results, exist_ok=True)\n",
        "\n",
        "dataset_args = data_configs.DATASETS[opts.dataset_type]\n",
        "#print(dataset_args)\n",
        "transforms_dict = dataset_args['transforms'](opts).get_transforms()\n",
        "\n",
        "#dpath = os.path.join('/content/gdrive/MyDrive/Datasets/shared/celeba/CelebA-HQ-img/','CelebA-HQ-img/')\n",
        "#print(transforms_dict)\n",
        "#print(os.path.isdir(data_path))\n",
        "dataset = InferenceDataset(root=data_path,\n",
        "                           transform=transforms_dict['transform_inference'],\n",
        "                           opts=opts)\n",
        "\n",
        "##print(dataset)\n",
        "dataloader = DataLoader(dataset, \n",
        "                        batch_size=opts.batch_size,\n",
        "                        shuffle=False,\n",
        "                        num_workers=int(4),\n",
        "                        drop_last=False)\n",
        "n_images = len(dataset)\n",
        "print(dataloader)\n",
        "avg_image = get_average_image(net, opts)\n",
        "print(avg_image.size())\n",
        "global_i = 0\n",
        "global_time = []\n",
        "all_latents = {}\n",
        "#print(opts.test_workers)\n",
        "resize_amount = (256, 256)\n",
        "for input_batch in tqdm(dataloader):\n",
        "  #print(global_i)\n",
        "  if global_i >= n_images:break\n",
        "  with torch.no_grad():\n",
        "    input_cuda = input_batch.cuda().float()\n",
        "    tic = time.time()\n",
        "    result_batch, result_latents = run_on_batch(input_cuda, net, opts, avg_image)\n",
        "    toc = time.time()\n",
        "    global_time.append(toc - tic)\n",
        "  for i in range(input_batch.shape[0]):\n",
        "    results = [tensor2im(result_batch[i][iter_idx]) for iter_idx in range(opts.n_iters_per_batch)]\n",
        "    im_path = dataset.paths[global_i]\n",
        "\n",
        "    # save step-by-step results side-by-side\n",
        "    \n",
        "    for idx, result in enumerate(results):\n",
        "      save_dir = os.path.join(out_path_results, str(idx))\n",
        "      os.makedirs(save_dir, exist_ok=True)\n",
        "      result.resize(resize_amount).save(os.path.join(save_dir, os.path.basename(im_path)))\n",
        "\n",
        "    # store all latents with dict pairs (image_name, latents)\n",
        "    all_latents[os.path.basename(im_path)] = result_latents[i]\n",
        "\n",
        "    global_i += 1\n",
        "\n",
        "stats_path = os.path.join(exp_path_results, 'stats.txt')\n",
        "result_str = 'Runtime {:.4f}+-{:.4f}'.format(np.mean(global_time), np.std(global_time))\n",
        "print(result_str)\n",
        "\n",
        "with open(stats_path, 'w') as f:\n",
        "    f.write(result_str)\n",
        "\n",
        "# save all latents as npy file\n",
        "np.save(os.path.join(exp_path_results, 'latents.npy'), all_latents)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUIcIAXQWCMV"
      },
      "source": [
        "# PSP FFHQ encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iz8P6nQtix9n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from tqdm import trange \n",
        "import argparse\n",
        "\n",
        "\n",
        "from models.psp import pSp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krp_APKbix9v",
        "outputId": "2aebb9c9-6347-4899-944b-58841e912b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'exp_dir': '', 'dataset_type': 'ffhq_encode', 'encoder_type': 'GradualStyleEncoder', 'input_nc': 3, 'label_nc': 0, 'batch_size': 8, 'test_batch_size': 8, 'workers': 8, 'test_workers': 2, 'learning_rate': 0.0001, 'optim_name': 'ranger', 'train_decoder': False, 'start_from_latent_avg': True, 'learn_in_w': False, 'lpips_lambda': 0.8, 'id_lambda': 0.1, 'l2_lambda': 1.0, 'w_norm_lambda': 0, 'lpips_lambda_crop': 0, 'l2_lambda_crop': 0, 'stylegan_weights': '', 'checkpoint_path': None, 'max_steps': 300000, 'image_interval': 100, 'board_interval': 50, 'val_interval': 2500, 'save_interval': 1000, 'resize_factors': None, 'device': 'cuda:0'}\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/psp_ffhq_encode.pt'\n",
        "#mod = torch.load(model,map_location='cpu')\n",
        "mod = torch.load(model,map_location='cuda:0')\n",
        "#mod['opts']['use_attention'] = False\n",
        "print(mod['opts'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw9bjKjmix9w",
        "outputId": "86e5c049-3ccf-408c-8d3a-970670ad8f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading encoder\n",
            "GradualStyleEncoder\n",
            "Loading ReStyle pSp from checkpoint: /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/psp_ffhq_encode.pt\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "opts = mod['opts']\n",
        "opts['use_attention'] = False\n",
        "opts['latent_avg'] = mod['latent_avg']\n",
        "opts['dataset_type']='ffhq_encode'\n",
        "opts['resize_outputs'] = True\n",
        "opts['use_stylegan'] =False\n",
        "opts['output_size'] =1024\n",
        "opts['n_iters_per_batch']=5\n",
        "opts = Namespace(**opts)\n",
        "opts.checkpoint_path = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/psp_ffhq_encode.pt'\n",
        "net = pSp(opts).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wDUTa7Cpix9w"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "from configs import data_configs\n",
        "from datasets.inference_dataset import InferenceDataset\n",
        "\n",
        "from utils.common import tensor2im\n",
        "from utils.inference_utils import run_on_batch, get_average_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wJZW8fRix9w",
        "outputId": "b9e32c4b-fe93-496e-ef4e-307524bb2e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f1a8bf61e50>\n",
            "torch.Size([3, 256, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/19 [00:04<01:27,  4.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 2/19 [00:09<01:17,  4.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 3/19 [00:13<01:11,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 4/19 [00:18<01:06,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 5/19 [00:22<01:02,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 6/19 [00:26<00:57,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 7/19 [00:31<00:53,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 8/19 [00:35<00:48,  4.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 9/19 [00:40<00:44,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 10/19 [00:44<00:39,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 11/19 [00:49<00:35,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 12/19 [00:53<00:31,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 13/19 [00:57<00:26,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 14/19 [01:02<00:22,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 15/19 [01:06<00:17,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 16/19 [01:11<00:13,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 17/19 [01:15<00:08,  4.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 18/19 [01:20<00:04,  4.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [01:21<00:00,  4.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime 3.8628+-0.6499\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/famous/'\n",
        "exp_dir = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/experiment/famous/'\n",
        "exp_path_results = os.path.join(exp_dir, 'psp_ffhq_encode')\n",
        "os.makedirs(exp_path_results, exist_ok=True)\n",
        "\n",
        "\n",
        "out_path_results = os.path.join('/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/', 'famous/psp_ffhq_encode/')\n",
        "os.makedirs(out_path_results, exist_ok=True)\n",
        "\n",
        "dataset_args = data_configs.DATASETS[opts.dataset_type]\n",
        "#print(dataset_args)\n",
        "transforms_dict = dataset_args['transforms'](opts).get_transforms()\n",
        "\n",
        "dataset = InferenceDataset(root=data_path,\n",
        "                           transform=transforms_dict['transform_inference'],\n",
        "                           opts=opts)\n",
        "\n",
        "##print(dataset)\n",
        "dataloader = DataLoader(dataset, \n",
        "                        batch_size=opts.batch_size,\n",
        "                        shuffle=False,\n",
        "                        num_workers=int(4),\n",
        "                        drop_last=False)\n",
        "n_images = len(dataset)\n",
        "print(dataloader)\n",
        "avg_image = get_average_image(net, opts)\n",
        "print(avg_image.size())\n",
        "global_i = 0\n",
        "global_time = []\n",
        "all_latents = {}\n",
        "#print(opts.test_workers)\n",
        "resize_amount = (256, 256)\n",
        "for input_batch in tqdm(dataloader):\n",
        "  #print(global_i)\n",
        "  if global_i >= n_images:break\n",
        "  with torch.no_grad():\n",
        "    input_cuda = input_batch.cuda().float()\n",
        "    tic = time.time()\n",
        "    result_batch, result_latents = run_on_batch(input_cuda, net, opts, avg_image)\n",
        "    toc = time.time()\n",
        "    global_time.append(toc - tic)\n",
        "  for i in range(input_batch.shape[0]):\n",
        "    results = [tensor2im(result_batch[i][iter_idx]) for iter_idx in range(opts.n_iters_per_batch)]\n",
        "    im_path = dataset.paths[global_i]\n",
        "\n",
        "    # save step-by-step results side-by-side\n",
        "    \n",
        "    for idx, result in enumerate(results):\n",
        "      save_dir = os.path.join(out_path_results, str(idx))\n",
        "      os.makedirs(save_dir, exist_ok=True)\n",
        "      result.resize(resize_amount).save(os.path.join(save_dir, os.path.basename(im_path)))\n",
        "\n",
        "    # store all latents with dict pairs (image_name, latents)\n",
        "    all_latents[os.path.basename(im_path)] = result_latents[i]\n",
        "\n",
        "    global_i += 1\n",
        "\n",
        "stats_path = os.path.join(opts.exp_dir, 'stats.txt')\n",
        "result_str = 'Runtime {:.4f}+-{:.4f}'.format(np.mean(global_time), np.std(global_time))\n",
        "print(result_str)\n",
        "\n",
        "with open(stats_path, 'w') as f:\n",
        "    f.write(result_str)\n",
        "\n",
        "# save all latents as npy file\n",
        "np.save(os.path.join(exp_path_results, 'latents.npy'), all_latents)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOSS"
      ],
      "metadata": {
        "id": "7TIa57bkB0nK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GGP3_BLpp0u-"
      },
      "outputs": [],
      "source": [
        "from argparse import ArgumentParser\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from criteria.lpips.lpips import LPIPS\n",
        "from datasets.gt_res_dataset import GTResDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Cj9NZcXRtsdW"
      },
      "outputs": [],
      "source": [
        "def run_on_step_output(step, output_path, data_path,batch_size,workers,mode):\n",
        "\n",
        "\ttransform = transforms.Compose([transforms.Resize((256, 256)),transforms.ToTensor(),transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "\tstep_outputs_path = os.path.join(output_path, step)\n",
        "\n",
        "\tprint('Loading dataset')\n",
        "\tdataset = GTResDataset(root_path=step_outputs_path,\n",
        "\t\t\t\t\t\t   gt_dir=data_path,\n",
        "\t\t\t\t\t\t   transform=transform)\n",
        "\t#print(dataset)\n",
        "\tprint('dataloader')\n",
        "\tdataloader = DataLoader(dataset,\n",
        "\t\t\t\t\t\t\tbatch_size=batch_size,\n",
        "\t\t\t\t\t\t\tshuffle=False,\n",
        "\t\t\t\t\t\t\tnum_workers=int(workers),\n",
        "\t\t\t\t\t\t\tdrop_last=True)\n",
        "\t#print(dataloader)\n",
        "\tif mode == 'lpips':\n",
        "\t\tloss_func = LPIPS(net_type='alex')\n",
        "\telif mode == 'l2':\n",
        "\t\tloss_func = torch.nn.MSELoss()\n",
        "\telse:\n",
        "\t\traise Exception('Not a valid mode!')\n",
        "\tloss_func.cuda()\n",
        "\n",
        "\tglobal_i = 0\n",
        "\tscores_dict = {}\n",
        "\tall_scores = []\n",
        "\tlosses = []\n",
        "\tprint('loss')\n",
        "\tfor result_batch, gt_batch in tqdm(dataloader):\n",
        "\t\t#print(result_batch)\n",
        "\t\tfor i in range(batch_size):\n",
        "\t\t\tloss = float(loss_func(result_batch[i:i+1].cuda(), gt_batch[i:i+1].cuda()))\n",
        "\t\t\tall_scores.append(loss)\n",
        "\t\t\tim_path = dataset.pairs[global_i][0]\n",
        "\t\t\tscores_dict[os.path.basename(im_path)] = loss\n",
        "\t\t\tglobal_i += 1\n",
        "\t\t\t#print(loss)\n",
        "\n",
        "\tall_scores = list(scores_dict.values())\n",
        "\t#print(all_scores)\n",
        "\t#print(scores_dict)\n",
        "\t#print(scores_dict.values())\n",
        "\tmean = np.mean(all_scores)\n",
        "\tstd = np.std(all_scores)\n",
        "\tresult_str = 'Average loss is {:.4f}+-{:.4f}'.format(mean, std)\n",
        "\tprint('Finished with ', step_outputs_path)\n",
        "\tprint(result_str)\n",
        "\n",
        "\tout_path = os.path.join(os.path.dirname(output_path), 'inference_metrics')\n",
        "\tif not os.path.exists(out_path):\n",
        "\t\tos.makedirs(out_path)\n",
        "\n",
        "\twith open(os.path.join(out_path, f'stat_{mode}_step_{step}.txt'), 'w') as f:\n",
        "\t\tf.write(result_str)\n",
        "\twith open(os.path.join(out_path, f'scores_{mode}_step_{step}.json'), 'w') as f:\n",
        "\t\tjson.dump(scores_dict, f)\n",
        "\treturn scores_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P2JFrNtqCl4",
        "outputId": "907f0044-7941-4012-9233-61ba1ed4b24b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "Running on step: 4\n",
            "################################################################################\n",
            "Loading dataset\n",
            "dataloader\n",
            "loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 146/146 [00:01<00:00, 103.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished with  /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_ffhq_encode/4\n",
            "Average loss is 0.0359+-0.0122\n",
            "{'1048.jpg': 0.055495671927928925, '1053.jpg': 0.030436605215072632, '1056.jpg': 0.02354595623910427, '1123.jpg': 0.02006179466843605, '1125.jpg': 0.017132798209786415, '1140.jpg': 0.02270878106355667, '1145.jpg': 0.021233048290014267, '1146.jpg': 0.020868664607405663, '116.jpg': 0.025159034878015518, '1211.jpg': 0.0610496960580349, '1220.jpg': 0.019951729103922844, '1222.jpg': 0.02361392043530941, '1255.jpg': 0.01849798485636711, '1259.jpg': 0.054645419120788574, '1262.jpg': 0.02319708839058876, '1278.jpg': 0.023503735661506653, '1288.jpg': 0.04194425791501999, '1396.jpg': 0.029527535662055016, '1454.jpg': 0.028481177985668182, '1475.jpg': 0.05798745155334473, '1492.jpg': 0.043055277317762375, '1495.jpg': 0.03255049139261246, '1500.jpg': 0.03302421793341637, '1501.jpg': 0.044437043368816376, '1516.jpg': 0.03398198261857033, '152.jpg': 0.04840312898159027, '1558.jpg': 0.029476147145032883, '1560.jpg': 0.040257252752780914, '1570.jpg': 0.04246752709150314, '1577.jpg': 0.02883661352097988, '1587.jpg': 0.03708253055810928, '1596.jpg': 0.049013566225767136, '1601.jpg': 0.04922686144709587, '1638.jpg': 0.03232094272971153, '1642.jpg': 0.03138257563114166, '1647.jpg': 0.03592539206147194, '168.jpg': 0.04812527447938919, '1725.jpg': 0.06292912364006042, '1731.jpg': 0.04482648894190788, '1790.jpg': 0.05916444957256317, '1814.jpg': 0.03790130838751793, '1815.jpg': 0.033576663583517075, '1821.jpg': 0.036735229194164276, '183.jpg': 0.05011547729372978, '198.jpg': 0.04766915738582611, '2000.jpg': 0.02873648703098297, '2005.jpg': 0.03720839321613312, '2007.jpg': 0.04882873594760895, '2042.jpg': 0.019434364512562752, '2054.jpg': 0.02907644584774971, '2056.jpg': 0.044142596423625946, '2068.jpg': 0.05365319177508354, '2077.jpg': 0.04205155372619629, '2102.jpg': 0.04097837954759598, '2147.jpg': 0.02273026667535305, '2265.jpg': 0.030549971386790276, '2280.jpg': 0.03542803227901459, '2287.jpg': 0.04821173474192619, '2300.jpg': 0.025231650099158287, '2408.jpg': 0.03406861796975136, '244.jpg': 0.03823110833764076, '2461.jpg': 0.03914033994078636, '2463.jpg': 0.034412235021591187, '2474.jpg': 0.030520182102918625, '2494.jpg': 0.04249526187777519, '2545.jpg': 0.048708777874708176, '255.jpg': 0.021617155522108078, '2560.jpg': 0.02695869468152523, '2562.jpg': 0.04708525165915489, '257.jpg': 0.02587289921939373, '2570.jpg': 0.04908325523138046, '2590.jpg': 0.05169104039669037, '260.jpg': 0.017402566969394684, '2620.jpg': 0.031348153948783875, '2635.jpg': 0.043721526861190796, '2636.jpg': 0.01998654380440712, '2641.jpg': 0.022130250930786133, '2646.jpg': 0.039571963250637054, '2677.jpg': 0.036488644778728485, '2688.jpg': 0.06099095195531845, '2689.jpg': 0.01765666902065277, '2691.jpg': 0.015434454195201397, '2703.jpg': 0.025424864143133163, '2719.jpg': 0.03814491629600525, '2767.jpg': 0.03960833698511124, '2769.jpg': 0.0348554290831089, '2797.jpg': 0.02972540818154812, '2801.jpg': 0.02418046072125435, '2830.jpg': 0.056109122931957245, '2840.jpg': 0.02158333733677864, '293.jpg': 0.027255982160568237, '2942.jpg': 0.0440831184387207, '2953.jpg': 0.058888982981443405, '2972.jpg': 0.03447861969470978, '2973.jpg': 0.0353325717151165, '3049.jpg': 0.03885604813694954, '3052.jpg': 0.036900103092193604, '317.jpg': 0.038429632782936096, '328.jpg': 0.03484152629971504, '3291.jpg': 0.014383266679942608, '35.jpg': 0.04058364778757095, '356.jpg': 0.014038494788110256, '36.jpg': 0.057608798146247864, '408.jpg': 0.0424191877245903, '4094.jpg': 0.04433772712945938, '415.jpg': 0.029284950345754623, '4174.jpg': 0.031990259885787964, '435.jpg': 0.059307895600795746, '445.jpg': 0.02750016748905182, '454.jpg': 0.01837172918021679, '4576.jpg': 0.0516880564391613, '474.jpg': 0.04676585644483566, '475.jpg': 0.03541674092411995, '482.jpg': 0.061090223491191864, '486.jpg': 0.03344292566180229, '533.jpg': 0.025936078280210495, '541.jpg': 0.03166380524635315, '569.jpg': 0.03148049861192703, '573.jpg': 0.02791461907327175, '586.jpg': 0.027436058968305588, '588.jpg': 0.03812220320105553, '596.jpg': 0.02675173431634903, '627.jpg': 0.04406198114156723, '631.jpg': 0.017254430800676346, '660.jpg': 0.014224668964743614, '663.jpg': 0.032305989414453506, '668.jpg': 0.03534373268485069, '67.jpg': 0.029842697083950043, '681.jpg': 0.041922323405742645, '724.jpg': 0.027107704430818558, '752.jpg': 0.037318482995033264, '76.jpg': 0.0354265421628952, '824.jpg': 0.04527860879898071, '828.jpg': 0.031574148684740067, '848.jpg': 0.04536621272563934, '890.jpg': 0.015812862664461136, '898.jpg': 0.019360503181815147, '914.jpg': 0.025242110714316368, '952.jpg': 0.0692431777715683, '962.jpg': 0.03667207434773445, '965.jpg': 0.036564625799655914, '968.jpg': 0.034556418657302856, '981.jpg': 0.0660337433218956, '989.jpg': 0.039325110614299774, '990.jpg': 0.03137565404176712, '991.jpg': 0.041198622435331345}\n",
            "146\n",
            "          img  l2 psp base\n",
            "0    1048.jpg     0.055496\n",
            "1    1053.jpg     0.030437\n",
            "2    1056.jpg     0.023546\n",
            "3    1123.jpg     0.020062\n",
            "4    1125.jpg     0.017133\n",
            "..        ...          ...\n",
            "141   968.jpg     0.034556\n",
            "142   981.jpg     0.066034\n",
            "143   989.jpg     0.039325\n",
            "144   990.jpg     0.031376\n",
            "145   991.jpg     0.041199\n",
            "\n",
            "[146 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "output_path = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_ffhq_encode/'\n",
        "data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/famous/'\n",
        "\n",
        "batch_size = 1\n",
        "workers = 4\n",
        "mode = 'l2'\n",
        "\n",
        "step='4'\n",
        "step_outputs_path = os.path.join(output_path, step)\n",
        "if os.path.isdir(step_outputs_path):\n",
        "  print('#' * 80)\n",
        "  print(f'Running on step: {step}')\n",
        "  print('#' * 80)\n",
        "  all_scores= run_on_step_output(step=step, output_path= output_path, data_path=data_path,batch_size=batch_size,\n",
        "                      workers=workers,mode=mode)\n",
        "  print(all_scores)\n",
        "  print(len(all_scores))\n",
        "  scores = {'img':all_scores.keys() , \n",
        "            'l2 psp base': all_scores.values()}\n",
        "  df = pd.DataFrame(scores,index = list(range(len(all_scores))))\n",
        "  print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_stylegan2_attention/'\n",
        "data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/famous/'\n",
        "batch_size = 1\n",
        "workers = 4\n",
        "mode = 'l2'\n",
        "\n",
        "step='4'\n",
        "step_outputs_path = os.path.join(output_path, step)\n",
        "if os.path.isdir(step_outputs_path):\n",
        "  print('#' * 80)\n",
        "  print(f'Running on step: {step}')\n",
        "  print('#' * 80)\n",
        "  all_scores= run_on_step_output(step=step, output_path= output_path, data_path=data_path,batch_size=batch_size,\n",
        "                      workers=workers,mode=mode)\n",
        "  df['l2 psp stylegan2'] = all_scores.values()\n",
        "  print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2VPvbto0uXx",
        "outputId": "11093326-4640-4ff9-878a-b3f906b3b4e1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "Running on step: 4\n",
            "################################################################################\n",
            "Loading dataset\n",
            "dataloader\n",
            "loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 146/146 [00:01<00:00, 101.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished with  /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_stylegan2_attention/4\n",
            "Average loss is 0.0352+-0.0121\n",
            "          img  l2 psp base  l2 psp stylegan2\n",
            "0    1048.jpg     0.055496          0.070964\n",
            "1    1053.jpg     0.030437          0.029259\n",
            "2    1056.jpg     0.023546          0.022495\n",
            "3    1123.jpg     0.020062          0.020812\n",
            "4    1125.jpg     0.017133          0.017382\n",
            "..        ...          ...               ...\n",
            "141   968.jpg     0.034556          0.030363\n",
            "142   981.jpg     0.066034          0.072204\n",
            "143   989.jpg     0.039325          0.039463\n",
            "144   990.jpg     0.031376          0.028654\n",
            "145   991.jpg     0.041199          0.039777\n",
            "\n",
            "[146 rows x 3 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_gansformer_attention/'\n",
        "data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/famous/'\n",
        "batch_size = 1\n",
        "workers = 4\n",
        "mode = 'l2'\n",
        "\n",
        "step='4'\n",
        "step_outputs_path = os.path.join(output_path, step)\n",
        "if os.path.isdir(step_outputs_path):\n",
        "  print('#' * 80)\n",
        "  print(f'Running on step: {step}')\n",
        "  print('#' * 80)\n",
        "  all_scores= run_on_step_output(step=step, output_path= output_path, data_path=data_path,batch_size=batch_size,\n",
        "                      workers=workers,mode=mode)\n",
        "  df['l2 psp gansformer'] = all_scores.values()\n",
        "  print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqJuQ8EB0vLd",
        "outputId": "9daae1cc-a23a-4d58-de39-4210568bf36f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "Running on step: 4\n",
            "################################################################################\n",
            "Loading dataset\n",
            "dataloader\n",
            "loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 146/146 [00:01<00:00, 132.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished with  /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_gansformer_attention/4\n",
            "Average loss is 0.0522+-0.0174\n",
            "          img  l2 psp base  l2 psp stylegan2  l2 psp gansformer\n",
            "0    1048.jpg     0.055496          0.070964           0.085880\n",
            "1    1053.jpg     0.030437          0.029259           0.038544\n",
            "2    1056.jpg     0.023546          0.022495           0.037449\n",
            "3    1123.jpg     0.020062          0.020812           0.028149\n",
            "4    1125.jpg     0.017133          0.017382           0.023909\n",
            "..        ...          ...               ...                ...\n",
            "141   968.jpg     0.034556          0.030363           0.052896\n",
            "142   981.jpg     0.066034          0.072204           0.110232\n",
            "143   989.jpg     0.039325          0.039463           0.046755\n",
            "144   990.jpg     0.031376          0.028654           0.033184\n",
            "145   991.jpg     0.041199          0.039777           0.046131\n",
            "\n",
            "[146 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7pAXxw1_A9Dz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760,
          "referenced_widgets": [
            "4d70260721564e67813f1b275c794f11",
            "fae31f1593d14cdaa72f5031e69f11bc",
            "a668d49da37d4bf0a3a90dfba8dbef85",
            "a6c1415d90cd43c18279d1e545929b71",
            "70ca88e3043e478fb0564e6dd6775800",
            "b565731bd9474e5595372d0d1c3753d7",
            "91b1df95f80442e6857720d4debadae0",
            "95503e78514646f2aba54c9c05df73e2",
            "f1e054ec1f274b218acb47dae31e31ff",
            "f719820a4ca44203ac05b39dd5e402fa",
            "1401acd7eb904148b0923f66bd9c1d26",
            "b40ea9fec6514be4bfb06a1333848ff7",
            "65384357eb0c4a55816564916afe55f7",
            "d5f590ac2b8848b99e14000049b9fc76",
            "e31b253fb59f4df1a0ac43e4740e3332",
            "a02b4c9c2cde40068358b683c3767401",
            "3e590aeb740043e69b1f8fffa4674fbc",
            "d0c0d755391f44b19a4b66c434f78345",
            "de8c0a593e904273a29057dd02251641",
            "d5b94718e712475296ace9d91628bb9c",
            "d8c539ebbff84fbf86f31bc46ede6624",
            "7fcefc1e46204438afd23d22d9295403"
          ]
        },
        "outputId": "8f2f112a-b9a0-406a-ad50-532defdb9603",
        "id": "vwYcpOCfA9Ot"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "Running on step: 4\n",
            "################################################################################\n",
            "Loading dataset\n",
            "dataloader\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d70260721564e67813f1b275c794f11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://raw.githubusercontent.com/richzhang/PerceptualSimilarity/master/lpips/weights/v0.1/alex.pth\" to /root/.cache/torch/hub/checkpoints/alex.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/5.87k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b40ea9fec6514be4bfb06a1333848ff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 146/146 [00:01<00:00, 83.56it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished with  /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_ffhq_encode/4\n",
            "Average loss is 0.1568+-0.0310\n",
            "          img  l2 psp base  l2 psp stylegan2  l2 psp gansformer  \\\n",
            "0    1048.jpg     0.055496          0.070964           0.085880   \n",
            "1    1053.jpg     0.030437          0.029259           0.038544   \n",
            "2    1056.jpg     0.023546          0.022495           0.037449   \n",
            "3    1123.jpg     0.020062          0.020812           0.028149   \n",
            "4    1125.jpg     0.017133          0.017382           0.023909   \n",
            "..        ...          ...               ...                ...   \n",
            "141   968.jpg     0.034556          0.030363           0.052896   \n",
            "142   981.jpg     0.066034          0.072204           0.110232   \n",
            "143   989.jpg     0.039325          0.039463           0.046755   \n",
            "144   990.jpg     0.031376          0.028654           0.033184   \n",
            "145   991.jpg     0.041199          0.039777           0.046131   \n",
            "\n",
            "     lpips psp base  \n",
            "0          0.268026  \n",
            "1          0.149615  \n",
            "2          0.171649  \n",
            "3          0.124700  \n",
            "4          0.108916  \n",
            "..              ...  \n",
            "141        0.210061  \n",
            "142        0.185201  \n",
            "143        0.158230  \n",
            "144        0.172371  \n",
            "145        0.140744  \n",
            "\n",
            "[146 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "output_path = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_ffhq_encode/'\n",
        "data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/famous/'\n",
        "batch_size = 1\n",
        "workers = 4\n",
        "mode = 'lpips'\n",
        "\n",
        "step='4'\n",
        "step_outputs_path = os.path.join(output_path, step)\n",
        "if os.path.isdir(step_outputs_path):\n",
        "  print('#' * 80)\n",
        "  print(f'Running on step: {step}')\n",
        "  print('#' * 80)\n",
        "  all_scores= run_on_step_output(step=step, output_path= output_path, data_path=data_path,batch_size=batch_size,\n",
        "                      workers=workers,mode=mode)\n",
        "  df['lpips psp base'] = all_scores.values()\n",
        "  print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_stylegan2_attention/'\n",
        "data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/famous/'\n",
        "batch_size = 1\n",
        "workers = 4\n",
        "mode = 'lpips'\n",
        "\n",
        "step='4'\n",
        "step_outputs_path = os.path.join(output_path, step)\n",
        "if os.path.isdir(step_outputs_path):\n",
        "  print('#' * 80)\n",
        "  print(f'Running on step: {step}')\n",
        "  print('#' * 80)\n",
        "  all_scores= run_on_step_output(step=step, output_path= output_path, data_path=data_path,batch_size=batch_size,\n",
        "                      workers=workers,mode=mode)\n",
        "  df['lpips psp stylegan2'] = all_scores.values()\n",
        "  print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08832d8c-e584-4b0e-b48e-c033a79ff65b",
        "id": "bKi0gVc3A9Ot"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "Running on step: 4\n",
            "################################################################################\n",
            "Loading dataset\n",
            "dataloader\n",
            "loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 146/146 [00:01<00:00, 90.05it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished with  /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_stylegan2_attention/4\n",
            "Average loss is 0.1555+-0.0309\n",
            "          img  l2 psp base  l2 psp stylegan2  l2 psp gansformer  \\\n",
            "0    1048.jpg     0.055496          0.070964           0.085880   \n",
            "1    1053.jpg     0.030437          0.029259           0.038544   \n",
            "2    1056.jpg     0.023546          0.022495           0.037449   \n",
            "3    1123.jpg     0.020062          0.020812           0.028149   \n",
            "4    1125.jpg     0.017133          0.017382           0.023909   \n",
            "..        ...          ...               ...                ...   \n",
            "141   968.jpg     0.034556          0.030363           0.052896   \n",
            "142   981.jpg     0.066034          0.072204           0.110232   \n",
            "143   989.jpg     0.039325          0.039463           0.046755   \n",
            "144   990.jpg     0.031376          0.028654           0.033184   \n",
            "145   991.jpg     0.041199          0.039777           0.046131   \n",
            "\n",
            "     lpips psp base  lpips psp stylegan2  \n",
            "0          0.268026             0.254263  \n",
            "1          0.149615             0.141816  \n",
            "2          0.171649             0.164234  \n",
            "3          0.124700             0.126313  \n",
            "4          0.108916             0.107607  \n",
            "..              ...                  ...  \n",
            "141        0.210061             0.217566  \n",
            "142        0.185201             0.170141  \n",
            "143        0.158230             0.157072  \n",
            "144        0.172371             0.171961  \n",
            "145        0.140744             0.141120  \n",
            "\n",
            "[146 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_gansformer_attention/'\n",
        "data_path = '/content/gdrive/MyDrive/Datasets/shared/celeba/famous/'\n",
        "batch_size = 1\n",
        "workers = 4\n",
        "mode = 'lpips'\n",
        "\n",
        "step='4'\n",
        "step_outputs_path = os.path.join(output_path, step)\n",
        "if os.path.isdir(step_outputs_path):\n",
        "  print('#' * 80)\n",
        "  print(f'Running on step: {step}')\n",
        "  print('#' * 80)\n",
        "  all_scores= run_on_step_output(step=step, output_path= output_path, data_path=data_path,batch_size=batch_size,\n",
        "                      workers=workers,mode=mode)\n",
        "  df['lpips psp gansformer'] = all_scores.values()\n",
        "  print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef324570-5abe-4d68-a5cf-24f9f70c9a42",
        "id": "avP_VjRLA9Ou"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "################################################################################\n",
            "Running on step: 4\n",
            "################################################################################\n",
            "Loading dataset\n",
            "dataloader\n",
            "loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 146/146 [00:01<00:00, 110.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished with  /content/gdrive/MyDrive/SPRING_2022/EC523/hw/proj/famous/psp_gansformer_attention/4\n",
            "Average loss is 0.2233+-0.0411\n",
            "          img  l2 psp base  l2 psp stylegan2  l2 psp gansformer  \\\n",
            "0    1048.jpg     0.055496          0.070964           0.085880   \n",
            "1    1053.jpg     0.030437          0.029259           0.038544   \n",
            "2    1056.jpg     0.023546          0.022495           0.037449   \n",
            "3    1123.jpg     0.020062          0.020812           0.028149   \n",
            "4    1125.jpg     0.017133          0.017382           0.023909   \n",
            "..        ...          ...               ...                ...   \n",
            "141   968.jpg     0.034556          0.030363           0.052896   \n",
            "142   981.jpg     0.066034          0.072204           0.110232   \n",
            "143   989.jpg     0.039325          0.039463           0.046755   \n",
            "144   990.jpg     0.031376          0.028654           0.033184   \n",
            "145   991.jpg     0.041199          0.039777           0.046131   \n",
            "\n",
            "     lpips psp base  lpips psp stylegan2  lpips psp gansformer  \n",
            "0          0.268026             0.254263              0.329205  \n",
            "1          0.149615             0.141816              0.230516  \n",
            "2          0.171649             0.164234              0.241612  \n",
            "3          0.124700             0.126313              0.179517  \n",
            "4          0.108916             0.107607              0.160152  \n",
            "..              ...                  ...                   ...  \n",
            "141        0.210061             0.217566              0.302215  \n",
            "142        0.185201             0.170141              0.258559  \n",
            "143        0.158230             0.157072              0.200484  \n",
            "144        0.172371             0.171961              0.233005  \n",
            "145        0.140744             0.141120              0.189145  \n",
            "\n",
            "[146 rows x 7 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['l2 diff']=df['l2 psp base']-df['l2 psp stylegan2']\n",
        "df['lpips diff']=df['lpips psp base']-df['lpips psp stylegan2']\n",
        "\n",
        "#print(df)\n",
        "\n",
        "newdf = df[df['l2 diff']>0.0]\n",
        "newdf.reset_index()\n",
        "#print(newdf)\n",
        "\n",
        "fin = newdf[newdf['lpips diff']>0.0]\n",
        "fin.reset_index()\n",
        "#print(fin)\n",
        "\n",
        "top = fin[fin['l2 diff']>0.006]\n",
        "print(top)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAfyOC-OicLH",
        "outputId": "b582ff1b-b9a7-4509-d358-84bffcdbd5bf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          img  l2 psp base  l2 psp stylegan2  l2 psp gansformer  \\\n",
            "23   1501.jpg     0.044437          0.034742           0.055626   \n",
            "43    183.jpg     0.050115          0.042740           0.064461   \n",
            "51   2068.jpg     0.053653          0.047468           0.059211   \n",
            "102    36.jpg     0.057609          0.046650           0.080071   \n",
            "107   435.jpg     0.059308          0.045888           0.067022   \n",
            "110  4576.jpg     0.051688          0.045616           0.064139   \n",
            "111   474.jpg     0.046766          0.039489           0.065791   \n",
            "128   681.jpg     0.041922          0.033320           0.061292   \n",
            "137   914.jpg     0.025242          0.018095           0.036129   \n",
            "138   952.jpg     0.069243          0.059208           0.072516   \n",
            "140   965.jpg     0.036565          0.030273           0.043173   \n",
            "\n",
            "     lpips psp base  lpips psp stylegan2  lpips psp gansformer   l2 diff  \\\n",
            "23         0.178448             0.177199              0.245556  0.009695   \n",
            "43         0.156004             0.143020              0.213159  0.007376   \n",
            "51         0.163997             0.149015              0.203489  0.006185   \n",
            "102        0.172072             0.155198              0.222012  0.010959   \n",
            "107        0.169293             0.162504              0.244988  0.013420   \n",
            "110        0.216818             0.192046              0.297158  0.006072   \n",
            "111        0.119231             0.109054              0.181134  0.007277   \n",
            "128        0.149038             0.134450              0.212175  0.008602   \n",
            "137        0.099635             0.088585              0.146015  0.007147   \n",
            "138        0.203456             0.185636              0.241581  0.010035   \n",
            "140        0.147480             0.143858              0.224360  0.006292   \n",
            "\n",
            "     lpips diff  \n",
            "23     0.001249  \n",
            "43     0.012984  \n",
            "51     0.014982  \n",
            "102    0.016874  \n",
            "107    0.006788  \n",
            "110    0.024773  \n",
            "111    0.010177  \n",
            "128    0.014588  \n",
            "137    0.011051  \n",
            "138    0.017819  \n",
            "140    0.003622  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "evaluate.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d70260721564e67813f1b275c794f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fae31f1593d14cdaa72f5031e69f11bc",
              "IPY_MODEL_a668d49da37d4bf0a3a90dfba8dbef85",
              "IPY_MODEL_a6c1415d90cd43c18279d1e545929b71"
            ],
            "layout": "IPY_MODEL_70ca88e3043e478fb0564e6dd6775800"
          }
        },
        "fae31f1593d14cdaa72f5031e69f11bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b565731bd9474e5595372d0d1c3753d7",
            "placeholder": "​",
            "style": "IPY_MODEL_91b1df95f80442e6857720d4debadae0",
            "value": "100%"
          }
        },
        "a668d49da37d4bf0a3a90dfba8dbef85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95503e78514646f2aba54c9c05df73e2",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1e054ec1f274b218acb47dae31e31ff",
            "value": 244408911
          }
        },
        "a6c1415d90cd43c18279d1e545929b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f719820a4ca44203ac05b39dd5e402fa",
            "placeholder": "​",
            "style": "IPY_MODEL_1401acd7eb904148b0923f66bd9c1d26",
            "value": " 233M/233M [00:01&lt;00:00, 218MB/s]"
          }
        },
        "70ca88e3043e478fb0564e6dd6775800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b565731bd9474e5595372d0d1c3753d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91b1df95f80442e6857720d4debadae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95503e78514646f2aba54c9c05df73e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e054ec1f274b218acb47dae31e31ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f719820a4ca44203ac05b39dd5e402fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1401acd7eb904148b0923f66bd9c1d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b40ea9fec6514be4bfb06a1333848ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65384357eb0c4a55816564916afe55f7",
              "IPY_MODEL_d5f590ac2b8848b99e14000049b9fc76",
              "IPY_MODEL_e31b253fb59f4df1a0ac43e4740e3332"
            ],
            "layout": "IPY_MODEL_a02b4c9c2cde40068358b683c3767401"
          }
        },
        "65384357eb0c4a55816564916afe55f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e590aeb740043e69b1f8fffa4674fbc",
            "placeholder": "​",
            "style": "IPY_MODEL_d0c0d755391f44b19a4b66c434f78345",
            "value": "100%"
          }
        },
        "d5f590ac2b8848b99e14000049b9fc76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8c0a593e904273a29057dd02251641",
            "max": 6009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5b94718e712475296ace9d91628bb9c",
            "value": 6009
          }
        },
        "e31b253fb59f4df1a0ac43e4740e3332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c539ebbff84fbf86f31bc46ede6624",
            "placeholder": "​",
            "style": "IPY_MODEL_7fcefc1e46204438afd23d22d9295403",
            "value": " 5.87k/5.87k [00:00&lt;00:00, 196kB/s]"
          }
        },
        "a02b4c9c2cde40068358b683c3767401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e590aeb740043e69b1f8fffa4674fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c0d755391f44b19a4b66c434f78345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de8c0a593e904273a29057dd02251641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b94718e712475296ace9d91628bb9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8c539ebbff84fbf86f31bc46ede6624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fcefc1e46204438afd23d22d9295403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}